%This section will discuss our research approach, described in Figure~\ref{fig:approach}. We divided our research into 4 steps. The first step performed was collecting data from Social Media. On this step, we gathered data from both YouTube and Twitter Social Media, using their officials APIs. From Twitter, we collected the tweets' texts, and from YouTube, we collected the users' comments.
%This section will discuss the research approach proposed, describe in the Figure \ref{fig:approach}. The first step taken is extracting data from social media API's. Text from tweets and youtube's comments are collected, then preprocessing is performed in collection data, including separation of the data in a serie temporal, according to the premiere date, tokenzation and removal links. The stopwords process will not considered in the model, because it acts negatively on the results obtained from Vader Lexicon.

%Next, we performed Vader Lexicon to get the Sentiment Score and Compound (mentioned in section \ref{vader}), and after, we realized the data separation in files, according to its polarity. In Data Analysis process, we already have the polarity of each text (sentence), then we calculate TF-IDF in created files, that we know about the important frequency terms in the whole document.